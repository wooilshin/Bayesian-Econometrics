{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d22950-9654-42e1-b06c-6b7e0b142e0a",
   "metadata": {},
   "source": [
    "<h1>Estimating Monetary Policy Reaction Function (M-H Algorithm)<h1\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770006af-0f32-4d25-b6c6-67201ca6d3e2",
   "metadata": {},
   "source": [
    " <h5> In a typical monetary policy reaction function, central banks set interest rates based on variables such as inflation, output gap, or unemployment. The reaction function can be modeled as:\r\n",
    "$$\r\n",
    "\\text{FFR}_t = \\rho \\cdot \\text{FFR}_{t-1} + (1 - \\rho) \\left( c + \\beta_1 \\cdot \\text{Inflation}_{t-1} + \\beta_2 \\cdot \\text{UN}_{t-1} \\right) + \\varepsilon_t\r\n",
    "$$\r\n",
    "\r\n",
    "where:\r\n",
    "\r\n",
    "- $ \\text{FFR}_t $ is the policy interest rate (e.g., the Federal Funds Rate),\r\n",
    "- $ \\rho $ is the smoothing parameter, showing the degree of inertia in rate-setting,\r\n",
    "- $ c $ is a constant term,\r\n",
    "- $ \\beta_1 $ is the response coefficient to inflation,\r\n",
    "- $ \\beta_2 $ is the response coefficient to unemployment,\r\n",
    "- $ \\varepsilon_t $ is a random error term with variance $ \\sigma^2 $.\n",
    " \\sigma^2 $.\n",
    "$ \\sigma^2 $.log-likelihood. <h5\\>\\(\\sigma^2\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff6e3b-73f3-454d-9d9e-a327d91085f7",
   "metadata": {},
   "source": [
    "<h2>Load library<h2\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ca9c3e-14c6-422e-844f-707ba37c23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta, norm, invgamma\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbeadd-7ba1-43d4-b234-d347f1474423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b48742ca-e005-4527-ad50-d76d09600188",
   "metadata": {},
   "source": [
    "<h2>Load data<h2\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76955ade-bed8-420e-8b7f-4966c2b0f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_excel('./Data.xlsx').values\n",
    "T = data.shape[0]\n",
    "\n",
    "# Extract variables\n",
    "FFR = data[:, 0]  # Federal funds rate\n",
    "Inflation = data[:, 1]  # Inflation rate\n",
    "UN = data[:, 2]  # Unemployment rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a37de92-ff6c-45c9-8c14-f39f733949ce",
   "metadata": {},
   "source": [
    "<h2>Set parameters<h2\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5faf0c0-9f00-467d-85c6-759b90cbb7af",
   "metadata": {},
   "source": [
    "$$\n",
    "\\rho \\sim \\text{Beta}(10, 10), \\quad c \\sim \\text{Normal}(5, 9), \\quad \\beta_1 \\sim \\text{Normal}(1, 0.25)\n",
    ",\\quad \\beta_2 \\sim \\text{Normal}(-1, 0.25), \\quad \\sigma^2 \\sim \\text{InverseGamma}(4, 12)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf498bd9-409b-44e0-a3df-654a627e62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specification dictionary\n",
    "Spec = {\n",
    "    'Data': data,\n",
    "    'MH': 2,\n",
    "    'nu': 15,\n",
    "    'alpha0': 10,             # beta distribution\n",
    "    'beta0': 10,              # beta distribution\n",
    "    'Normal_mu': np.array([5, 1, -1]),                  # normal distribution\n",
    "    'Normal_V': np.array([9, 0.25, 0.25]),              # normal distribution\n",
    "    'a0': 8,                  # inverse gamma distribution\n",
    "    'd0': 24,                 # inverse gamma distribution\n",
    "    'ind_beta': 1,              # index pointing to the Beta distribution \n",
    "    'ind_Normal': [2, 3, 4],    # index pointing to the normal distribution\n",
    "    'ind_IG': 5                 # index pointing to the inverse gamma distribution\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c06557-dbab-4e57-8e06-3c7c0bc147f0",
   "metadata": {},
   "source": [
    "<h2>Define log-likelihood function<h2\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f3a6c-33cc-4654-b69a-4bf85bc08a67",
   "metadata": {},
   "source": [
    "The log-likelihood function compares the actual observed policy rate with the rate implied by the reaction function for each time period:\n",
    "\n",
    "1. Calculate Expected Policy Rate:\n",
    "\n",
    "   Based on the reaction function and the current parameter values, compute the expected interest rate for each period\n",
    "   , given the lagged inflation and unemployment values.\n",
    "\n",
    "2. Calculate Residuals:\n",
    "\n",
    "   The residual is the difference between the observed and the expected rate \n",
    "\n",
    "3. Construct Log-Likelihood:\n",
    "\n",
    "   Assuming Gaussian errors, the log-likelihood of observing each rate, given the parameters, is:\n",
    "   \n",
    "   $$\n",
    "   \\ln L_t = -\\frac{1}{2} \\ln(2 \\pi \\sigma^2) - \\frac{(\\text{FFR}_t - \\text{Ybar}_t)^2}{2 \\sigma^2}\n",
    "   $$\n",
    "   \n",
    "   Summing this over all observations provides the total log-likelihood:\n",
    "   \n",
    "   $$\n",
    "   \\text{lnlik} = \\sum_{t} \\ln L_t\n",
    "   $$\n",
    "\n",
    "This total log-likelihood reflects the fit of the reaction function to the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fb467-2bb1-4ffb-bcd9-e08a9b919db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model assumes that the errors (or residuals) between the observed interest rate (FFR_t) and the predicted interest rate (Ybar_t)\n",
    "# follow a normal (Gaussian) distribution. Taking the natural log of the likelihood (to make it easier to work with) \n",
    "# results in the log-likelihood for each observation. Lastly the total log-likelihood is obtained by summing the individual \n",
    "# log-likelihoods across all observations \n",
    "\n",
    "def lnlik(theta, Spec):\n",
    "    Data = Spec['Data']\n",
    "    FFR, Inflation, UN = Data[:, 0], Data[:, 1], Data[:, 2]\n",
    "\n",
    "    rho, c, beta1, beta2, sig2 = theta\n",
    "    T = len(FFR)\n",
    "\n",
    "    # Define Yt and Ybar based on model\n",
    "    Yt = FFR[1:T]\n",
    "    Ybar = (1 - rho) * c + (1 - rho) * beta1 * Inflation[:T-1] + (1 - rho) * beta2 * UN[:T-1] + rho * FFR[:T-1]\n",
    "    \n",
    "    # Compute log-likelihood\n",
    "    sigma = sig2 * np.ones(T - 1)\n",
    "    lnLm = -0.5 * np.log(2 * np.pi * sigma) - 0.5 * ((Yt - Ybar) ** 2 / sigma)\n",
    "    return np.sum(lnLm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508019a7-95b2-40e1-9946-389702038e6e",
   "metadata": {},
   "source": [
    "<h2>Define Log-prior function<h2\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888da09d-3e09-4d4e-af35-7981e9d18d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the log of the prior probability density for each parameter based on their specified distributions:\n",
    "\n",
    "def lnprior(theta, Spec):\n",
    "    # Unpack hyperparameters\n",
    "    alpha0, beta0 = Spec['alpha0'], Spec['beta0']\n",
    "    Normal_mu, Normal_V = Spec['Normal_mu'], Spec['Normal_V']\n",
    "    a0, d0 = Spec['a0'], Spec['d0']\n",
    "\n",
    "    # Unpack parameter indices\n",
    "    ind_beta = Spec['ind_beta']\n",
    "    ind_Normal = Spec['ind_Normal']\n",
    "    ind_IG = Spec['ind_IG']\n",
    "\n",
    "    # Priors\n",
    "    lnPrior = beta.logpdf(theta[ind_beta], alpha0, beta0)  # Beta prior for rho\n",
    "    lnPrior += np.sum(norm.logpdf(theta[ind_Normal], Normal_mu, np.sqrt(Normal_V)))  # Normal priors for (c, beta1, beta2)\n",
    "    lnPrior += invgamma.logpdf(theta[ind_IG], a0 / 2, scale=d0 / 2)  # Inverse-Gamma prior for sig2\n",
    "    \n",
    "    return lnPrior\n",
    "\n",
    "# log-posterior\n",
    "\n",
    "def lnpost(theta, Spec):\n",
    "    lnL = lnlik(theta, Spec)\n",
    "    lnPrior = lnprior(theta, Spec)\n",
    "    return lnL + lnPrior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db93839f-50fd-405c-8c22-6ec11be19782",
   "metadata": {},
   "source": [
    "<h2>Define parameter constraints\n",
    "    <h2\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa5295-bf37-49d2-b68a-71b41229d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramconst(theta, Spec):\n",
    "    # Check that rho is between 0 and 1 and sig2 > 0\n",
    "    valid = True\n",
    "    valid &= (0 < theta[0] < 1)  # rho in (0,1)\n",
    "    valid &= (theta[4] > 0)  # sig2 > 0\n",
    "    return valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880c36b-df88-411a-aa47-e052ec92f121",
   "metadata": {},
   "source": [
    "<h2>Define Metropolis-Hastings Sampler<h2\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25fa5b8b-9841-488a-ab2f-f6512aa364d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function MCMC performs Markov Chain Monte Carlo (MCMC) sampling using the Metropolis-Hastings algorithm\n",
    "# to approximate the posterior distribution of a set of parameters based on a given log-posterior function.\n",
    "\n",
    "\n",
    "def MCMC(lnpost, paramconst, n0, n1, theta_hat, V, freq, Spec):\n",
    "    samples = []\n",
    "    theta = theta_hat\n",
    "    accepted = 0\n",
    "\n",
    "    for i in range(n0 + n1):\n",
    "        # Propose new sample from multivariate normal around current theta\n",
    "        proposal = np.random.multivariate_normal(theta, V)\n",
    "\n",
    "        # Check parameter constraints\n",
    "        if not paramconst(proposal, Spec):\n",
    "            continue\n",
    "\n",
    "        # Calculate acceptance ratio\n",
    "        log_posterior_current = lnpost(theta, Spec)\n",
    "        log_posterior_proposal = lnpost(proposal, Spec)\n",
    "        acceptance_ratio = np.exp(log_posterior_proposal - log_posterior_current)\n",
    "\n",
    "        # Accept or reject\n",
    "        if np.random.rand() < acceptance_ratio:\n",
    "            theta = proposal\n",
    "            accepted += 1\n",
    "\n",
    "        # Store sample if beyond burn-in period and at the right frequency\n",
    "        if i >= n0 and (i - n0) % freq == 0:\n",
    "            samples.append(theta)\n",
    "\n",
    "    samples = np.array(samples)\n",
    "    acceptance_rate = accepted / (n0 + n1)\n",
    "    return samples, acceptance_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f6084-6132-4433-8cf2-83ede4b4de38",
   "metadata": {},
   "source": [
    "<h2>Run MCMC Sampler<h2\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6a1fc-4505-400b-9174-4419cfc7fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values and proposal covariance matrix for MCMC\n",
    "theta0 = np.array([0.5, *Spec['Normal_mu'], 0.5 * Spec['a0'] / (0.5 * Spec['d0'] - 1)])\n",
    "V = np.diag([0.1] * len(theta0))  # Simplified covariance matrix, may require tuning\n",
    "\n",
    "# MCMC parameters\n",
    "n0 = 2000  # Burn-in period\n",
    "n1 = 20000  # Number of MCMC samples\n",
    "freq = 500  # Frequency of storing samples\n",
    "\n",
    "# Run MCMC\n",
    "samples, acceptance_rate = MCMC(lnpost, paramconst, n0, n1, theta0, V, freq, Spec)\n",
    "print(\"Acceptance rate:\", acceptance_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde90141-f9b3-4e30-9678-48d6bb02b62c",
   "metadata": {},
   "source": [
    "<h2>Plot<h2\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be17057-8ae5-4760-807f-3495b70153db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting prior and posterior for the first parameter as an example\n",
    "prior = 1 + np.random.randn(len(samples))\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(prior, bins=30, density=True, alpha=0.5, label='Prior', linestyle='--')\n",
    "plt.hist(samples[:, 2], bins=30, density=True, alpha=0.7, label='Posterior')\n",
    "plt.xlabel(r'$\\beta_1$')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
